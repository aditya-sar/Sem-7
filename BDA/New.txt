        ### 1. hadoop version

       
        
        
        ### 2. hadoop fs -Is
        
         
        Found 61 items
        -rw-r--r-- 1 training supergroup drwxr-xr-x - training supergroup
        -rw-r--r-- 1 training supergroup drwxr-xr-x - training supergroup drwxr-xr-x - training supergroup
        -rw-r--r-- 1 training supergroup drwxr-xr-x - training supergroup drwxr-xr-x - training supergroup
        -rw-r--r-- 1 training supergroup drwxr-xr-x - training supergroup
        -rw-r--r-- 1 training supergroup drwxr-xr-x - training supergroup drwxr-xr-x - training supergroup drwxr-xr-x - training supergroup drwxr-xr-x - training supergroup drwxr-xr-x - training supergroup drwxr-xr-x - training supergroup drwxr-xr-x - training supergroup drwxr-xr-x - training supergroup drwxr-xr-x - training supergroup drwxr-xr-x - training supergroup drwxr-xr-x - training supergroup drwxr-xr-x - training supergroup drwxr-xr-x - training supergroup
        -rw-r--r-- 1 training supergroup
        -rw-r--r-- 1 training supergroup drwxr-xr-x - training supergroup
         
        
        1390 2015-10-02 20:20 /user/training/Books
        0 2019-10-22 23:32 /user/training/H
        18 2019-09-24 23:28 /user/training/SSAhadoop.txt
        0 2014-08-17 03:50 /user/training/WeatherData
        0 2015-10-17 02:34 /user/training/ sqoop
        23 2015-11-29 23:36 /user/training/a
        0 2019-10-23 23:02 /user/training/angeloutdir
        0 2019-08-27 02:45 /user/training/apache hadoop
        2944 2015-09-26 02:37 /user/training/bookinfo
        0 2015-09-20 01:38 /user/training/class2009 dir1
        81 2015-09-18 21:05 /user/training/deptinfo
        0 2014-08-17 01:59 /user/training/dir1
        0 2015-09-12 02:42 /user/training/dir10
        0 2015-09-19 02:00 /user/training/dir100
        0 2015-09-19 02:42 /user/training/dir1000
        0 2014-08-22 02:30 /user/training/dir11
        0 2014-08-22 02:35 /user/training/dir12
        0 2014-08-17 01:59 /user/training/dir2
        0 2014-08-17 01:59 /user/training/dir3
        0 2014-08-17 01:59 /user/training/dir4
        0 2014-08-17 01:59 /user/training/dir5
        0 2014-08-17 03:03/user/training/dir6
        0 2014-08-17 03:04 /user/training/dir7
        0 2014-08-17 04:22 /user/training/dir9
        1390 2015-10-02 20:22 /user/training/dirbook
        72 2019-10-23 02:48 /user/training/dumA.txt
        0 2015-10-17 02:14 /user/training/emp
         
        drwxr-xr-x - training supergroup drwxr-xr-x - training supergroup drwxr-xr-x - training supergroup drwxr-xr-x - training supergroup drwxr-xr-x - training supergroup drwxr-xr-x - training supergroup drwxr-xr-x - training supergroup drwxr-xr-x - training supergroup
        -rw-r--r-- 1 training supergroup
        -rw-r--r-- 1 training supergroup
        -rw-r--r-- 1 training supergroup
        -rw-r--r-- 1 training supergroup
        -rw-r--r-- 1 training supergroup drwxr-xr-x - training supergroup
        -rw-r--r-- 1 training supergroup
        -rw-r--r-- 1 training supergroup
        -rw-r--r-- 1 training supergroup
        -rw-r--r-- 1 training supergroup
        -rw-r--r-- 1 training supergroup
        -rw-r--r-- 1 training supergroup drwxr-xr-x - training supergroup
        -rw-r--r-- 1 training supergroup
        -rw-r--r-- 1 training supergroup drwxr-xr-x - training supergroup
        -rw-r--r-- 1 training supergroup
        -rw-r--r-- 1 training supergroup drwxr-xr-x - training supergroup drwxr-xr-x - training supergroup drwxr-xr-x - training supergroup drwxr-xr-x - training supergroup drwxr-xr-x - training supergroup
        -rw-r--r-- 1 training supergroup drwxr-xr-x - training supergroup
        -rw-r--r-- 1 training supergroup 
        ### 3. hadoop fs -df hdfs:/
         
        0 2015-10-17 02:34 /user/training/emp2
        0 2015-10-10 23:18 /user/training/emp dir
        0 2015-10-17 02:26 /user/training/employee
        0 2015-10-17 23:39 /user/training/employee2
        0 2015-10-17 23:42 /user/training/employee3
        0 2019-08-29 01:14 /user/training/hadoop
        0 2022-07-27 22:54 /user/training/hadoop2
        0 2019-08-29 01:16 /user/training/hadoop7
        44 2017-03-22 23:31 /user/training/inputWC.txt
        50 2019-10-23 23:00 /user/training/j.txt
        69 2015-10-10 02:35 /user/training/join
        105 2015-10-10 02:38 /user/training/join2
        50 2019-10-23 03:35 /user/training/juhihadoop.txt
        0 2017-03-22 23:33/user/training/outputWC.txt
        48 2019-10-23 02:58 /user/training/owners.txt
        48 2019-10-23 03:02 /user/training/pets.txt
        48 2019-10-23 02:55 /user/training/pig
        32 2015-10-04 02:04 /user/training/pig1
        90 2015-11-23 03:12 /user/training/poem
        90 2015-09-12 02:41 /user/training/poem912
        0 2019-08-27 02:14 /user/training/priya
        20 2019-10-23 01:52 /user/training/sample.txt
        18 2019-08-29 01:50 /user/training/sampIe3.txt
        0 2019-10-23 03:38 /user/training/sampleoutdir
        194 2019-10-23 01:56 /user/training/sj.txt
        148 2019-10-23 02:10 /user/training/sjd.txt
        0 2015-10-10 03:53/user/training/str
        0 2015-10-17 01:26 /user/training/stud
        0 2015-10-17 01:42 /user/training/stud1
        0 2015-10-17 01:43/user/training/stud2
        0 2015-10-17 02:01 /user/training/student
        86 2015-10-10 03:40 /user/training/table2
        0 2015-09-12 02:33/user/training/user
        59 2015-10-10 00:56 /user/training/wordcount
         
        Filesystem	Size	Used	Avail Use%
        hdfs:/	18611908608	97929182	12461744128	0%
        
        ### 4. hadoop fs -count hdfs:/
        
        280	352	94013607 hdfs://IocaIhost/ ### 5. hadoop fsck - /
        FSCK started by training from /127.0.0.1 for path / at Thu Jul 28 22:23:54 PDT 2022
         
        /hbase/-ROOT-/70236052/.oIdIogs/hIog.1309921036526: Under replicated
        blk -7951519016048452162 1042. Target Replicas is 3 but found 1 replica(s).
        
        /hbase/-ROOT-/70236052/.regioninfo: Under replicated bIk_4111342483554438822_1040. Target Replicas is 3 but found 1 replica(s).
        
        /hbase/.META./1028785192/.oIdIogs/hIog.1309921036692: Under replicated blk 3938822511733381919 1043. Target Replicas is 3 but found 1 replica(s).
        
        /hbase/.META./1028785192/.regioninfo: Under replicated bIk_2455092764027271611_1042. Target Replicas is 3 but found 1 replica(s).
        
        /hbase/hbase.version: Under replicated bIk_1723987066918777078_1038. Target Replicas is 3 but found 1 replica(s).
        
        
        /user/training/apache_hadoop/b.txt: Under replicated bIk_-3399004998250828873_2574. Target Replicas is 2 but found 1 replica(s).
        
        /user/training/apache hadoop/priya1/purchase1.txt: Under replicated blk -8384833456743756432 2608. Target Replicas is 2 but found 1 replica(s).
        
        
        /var/lib/hadoop-0.20/cache/mapred/mapred/staging/training/.staging/job 201408170019 0004/job.jar: Under replicated blk 3911109964028392820_1319. Target Replicas is 10 but found 1 replica(s).
        
        /var/lib/hadoop-0.20/cache/mapred/mapred/staging/training/.staging/job 201408170019 0025/job.jar:
        Under replicated blk 9033544763443023253 1482. Target Replicas is 10 but found 1 replica(s).
        
        /var/lib/hadoop-0.20/cache/mapred/mapred/staging/training/.staging/job 201408170019 0027/job.jar:
        Under replicated blk -4698454349821956552 1490. Target Replicas is 10 but found 1 replica(s).
        
        /var/lib/hadoop-0.20/cache/mapred/mapred/staging/training/.staging/job 201508230248 0002/job.jar: Under replicated bIk_-8850810541639539894_1514. Target Replicas is 10 but found 1 replica(s).
        
        /var/lib/hadoop-0.20/cache/mapred/mapred/staging/training/.staging/job_201508230248_0004/job.jar: Under replicated bIk_5462879686383900339_1526. Target Replicas is 10 but found 1 replica(s).
        
        /var/lib/hadoop-0.20/cache/mapred/mapred/staging/training/.staging/job_201508230248_0004/job.split: Under replicated bIk_8266023462158998529_1527. Target Replicas is 10 but found 1 replica(s).
        
        /var/lib/hadoop-0.20/cache/mapred/mapred/staging/training/.staging/job_201509190216_0006/job.jar: Under replicated bIk_-466695806927308856_1590. Target Replicas is 10 but found 1 replica(s).
        
        /var/lib/hadoop-0.20/cache/mapred/mapred/staging/training/.staging/job 201509190216 0007/job.jar: Under replicated bIk_-2135089505851887935_1591. Target Replicas is 10 but found 1 replica(s).
        
        /var/lib/hadoop-0.20/cache/mapred/mapred/staging/training/.staging/job_201509190216_0013/job.jar: Under replicated blk -5600096774557289154 1634. Target Replicas is 10 but found 1 replica(s).
         
        
        /var/lib/hadoop-0.20/cache/mapred/mapred/staging/training/.staging/job 201509190216 0017/job.jar:
        Under replicated blk 5567851633779790418 1661. Target Replicas is 10 but found 1 replica(s).
        
        /var/lib/hadoop-0.20/cache/mapred/mapred/staging/training/.staging/job_201509190216_0018/job.jar: Under replicated bIk_-234736479035488268_1662. Target Replicas is 10 but found 1 replica(s).
        
        /var/lib/hadoop-0.20/cache/mapred/mapred/staging/training/.staging/job 201509190216 0019/job.jar: Under replicated bIk_4158434274791493013_1663. Target Replicas is 10 but found 1 replica(s).
        
        /var/lib/hadoop-0.20/cache/mapred/mapred/staging/training/.staging/job_201509190216_0020/job.jar: Under replicated bIk_7935181994335701439_1664. Target Replicas is 10 but found 1 replica(s).
        
        /var/lib/hadoop-0.20/cache/mapred/mapred/staging/training/.staging/job_201509190216_0021/job.jar: Under replicated bIk_5469356412035500418_1665. Target Replicas is 10 but found 1 replica(s).
        
        /var/lib/hadoop-0.20/cache/mapred/mapred/staging/training/.staging/job_201509190216_0022/job.jar: Under replicated bIk_3560726352007957352_1666. Target Replicas is 10 but found 1 replica(s).
        
        /var/lib/hadoop-0.20/cache/mapred/mapred/staging/training/.staging/job 201509190216 0023/job.jar:
        Under replicated blk 7230413706823514300 1667. Target Replicas is 10 but found 1 replica(s).
        
        /var/lib/hadoop-0.20/cache/mapred/mapred/staging/training/.staging/job_201509190216_0043/job.jar: Under replicated blk -7061194376768727047 1865. Target Replicas is 10 but found 1 replica(s).
        
        /var/lib/hadoop-0.20/cache/mapred/mapred/staging/training/.staging/job 201509190216 0043/Iibjars/ant-
        contrib-1.0b3.jar: Under replicated blk -7857033371648641748 1854. Target Replicas is 10 but found 1 replica(s).
        
        /var/lib/hadoop-0.20/cache/mapred/mapred/staging/training/.staging/job 201509190216 0043/Iibjars/ant- eclipse-1.0-jvm1.2.jar: Under replicated blk -5734117897169422328 1852. Target Replicas is 10 but found 1 replica(s).
        
        /var/lib/hadoop-0.20/cache/mapred/mapred/staging/training/.staging/job_201509190216_0043/Iibjars/avro
        -1.5.4.jar: Under replicated bIk_-4396417076346037770_1860. Target Replicas is 10 but found 1 replica(s).
        
        /var/lib/hadoop-0.20/cache/mapred/mapred/staging/training/.staging/job 201509190216 0043/Iibjars/avro
        -ipc-1.5.4.jar: Under replicated bIk_-1493576512569211422_1859. Target Replicas is 10 but found 1 replica(s).
        
        /var/lib/hadoop-0.20/cache/mapred/mapred/staging/training/.staging/job_201509190216_0043/Iibjars/avro
        -mapred-1.5.4.jar: Under replicated bIk_4607638158339229384_1853. Target Replicas is 10 but found 1 replica(s).
        
        /var/lib/hadoop-0.20/cache/mapred/mapred/staging/training/.staging/job_201509190216_0043/Iibjars/com mons-io-1.4.jar: Under replicated bIk_-5658901819709288166_1861. Target Replicas is 10 but found 1 replica(s).
         
        ### 6. hadoop balancer
        
        Time Stamp	Iteration# Bytes Already Moved Bytes Left To Move Bytes Being Moved 22/07/28 22:25:33 INFO net.NetworkTopoIogy: Adding a new node: /defauIt-rack/127.0.0.1:50010 22/07/28 22:25:33 INFO balancer.Balancer: 0 over utilized nodes:
        22/07/28 22:25:33 INFO balancer.Balancer: 1 under utilized nodes: 127.0.0.1:50010 The cluster is balanced. Exiting...
        Balancing took 268.0 milliseconds
        
        ### 7. hadoop fs -mkdir /user/training/hadoop3
        
        ### 8. hadoop fs -put data/sample.txt /user/training/hadoop3 ### 9. hadoop fs -Is /user/training/hadoop3
         
        Found 1 items
        -rw-r--r-- 1 training supergroup
         
        
        0 2022-07-28 22:30 /user/training/hadoop3/sample.txt
         
        
        ### 10. hadoop fs -put data/retail /user/training/hadoop3
        
        ### 11. hadoop fs -Is
        
        Found 62 items
        -rw-r--r--  1 training supergroup	1390 2015-10-02 20:20 /user/training/Books
        drwxr-xr-x  - training supergroup	0 2019-10-22 23:32 /user/training/H
        -rw-r--r--  1 training supergroup	18 2019-09-24 23:28 /user/training/SSAhadoop.txt
        drwxr-xr-x  - training supergroup	0 2014-08-17 03:50 /user/training/WeatherData
        drwxr-xr-x  - training supergroup	0 2015-10-17 02:34 /user/training/ sqoop
        -rw-r--r--  1 training supergroup	23 2015-11-29 23:36 /user/training/a
        drwxr-xr-x  - training supergroup	0 2019-10-23 23:02 /user/training/angeloutdir
        drwxr-xr-x  - training supergroup	0 2019-08-27 02:45 /user/training/apache hadoop
        -rw-r--r--  1 training supergroup	2944 2015-09-26 02:37 /user/training/bookinfo
        drwxr-xr-x  - training supergroup	0 2015-09-20 01:38 /user/training/class2009 dir1
        -rw-r--r--  1 training supergroup	81 2015-09-18 21:05 /user/training/deptinfo
        drwxr-xr-x  - training supergroup	0 2014-08-17 01:59 /user/training/dir1
        drwxr-xr-x  - training supergroup	0 2015-09-12 02:42 /user/training/dir10
        drwxr-xr-x  - training supergroup	0 2015-09-19 02:00 /user/training/dir100
        drwxr-xr-x  - training supergroup	0 2015-09-19 02:42 /user/training/dir1000
        drwxr-xr-x  - training supergroup	0 2014-08-22 02:30 /user/training/dir11
        drwxr-xr-x  - training supergroup	0 2014-08-22 02:35 /user/training/dir12
        drwxr-xr-x  - training supergroup	0 2014-08-17 01:59 /user/training/dir2
        drwxr-xr-x  - training supergroup	0 2014-08-17 01:59 /user/training/dir3
        drwxr-xr-x  - training supergroup	0 2014-08-17 01:59 /user/training/dir4
        drwxr-xr-x - training supergroup 0 2014-08-17 01:59 /user/training/dir5 drwxr-xr-x - training supergroup 0 2014-08-17 03:03/user/training/dir6 drwxr-xr-x  - training supergroup    0 2014-08-17 03:04 /user/training/dir7
        drwxr-xr-x  - training supergroup	0 2014-08-17 04:22 /user/training/dir9
        -rw-r--r--  1 training supergroup	1390 2015-10-02 20:22 /user/training/dirbook
        -rw-r--r--  1 training supergroup	72 2019-10-23 02:48 /user/training/dumA.txt
         
        drwxr-xr-x drwxr-xr-x drwxr-xr-x drwxr-xr-x drwxr-xr-x drwxr-xr-x drwxr-xr-x drwxr-xr-x drwxr-xr-x drwxr-xr-x
         
        -	training supergroup
        -	training supergroup
        -	training supergroup
        -	training supergroup
        -	training supergroup
        -	training supergroup
        -	training supergroup
        -	training supergroup
        -	training supergroup
        -	training supergroup
         
        0 2015-10-17 02:14 /user/training/emp
        0 2015-10-17 02:34 /user/training/emp2
        0 2015-10-10 23:18 /user/training/emp dir
        0 2015-10-17 02:26 /user/training/employee
        0 2015-10-17 23:39 /user/training/employee2
        0 2015-10-17 23:42 /user/training/employee3
        0 2019-08-29 01:14 /user/training/hadoop
        0 2022-07-27 22:54 /user/training/hadoop2
        0 2022-07-28 22:33/user/training/hadoop3
        0 2019-08-29 01:16 /user/training/hadoop7
         
        -rw-r--r-- 1 training supergroup
        -rw-r--r-- 1 training supergroup
        -rw-r--r-- 1 training supergroup
        -rw-r--r-- 1 training supergroup
        -rw-r--r-- 1 training supergroup
         
        44 2017-03-22 23:31 /user/training/inputWC.txt
        50 2019-10-23 23:00 /user/training/j.txt
        69 2015-10-10 02:35 /user/training/join
        105 2015-10-10 02:38 /user/training/join2
        50 2019-10-23 03:35 /user/training/juhihadoop.txt
         
        drwxr-xr-x
         
        -	training supergroup
         
        0 2017-03-22 23:33/user/training/outputWC.txt
         
        -rw-r--r-- 1 training supergroup
        -rw-r--r-- 1 training supergroup
        -rw-r--r-- 1 training supergroup
        -rw-r--r-- 1 training supergroup
        -rw-r--r-- 1 training supergroup
        -rw-r--r-- 1 training supergroup
         
        48 2019-10-23 02:58 /user/training/owners.txt
        48 2019-10-23 03:02 /user/training/pets.txt
        48 2019-10-23 02:55 /user/training/pig
        32 2015-10-04 02:04 /user/training/pig1
        90 2015-11-23 03:12 /user/training/poem
        90 2015-09-12 02:41 /user/training/poem912
         
        drwxr-xr-x
         
        -	training supergroup
         
        0 2019-08-27 02:14 /user/training/priya
         
        -rw-r--r-- 1 training supergroup
        -rw-r--r-- 1 training supergroup
         
        20 2019-10-23 01:52 /user/training/sample.txt
        18 2019-08-29 01:50 /user/training/sampIe3.txt
         
        drwxr-xr-x
         
        -	training supergroup
         
        0 2019-10-23 03:38 /user/training/sampleoutdir
         
        
        ### 12. hadoop fs -du hadoop3/retail
        
        Found 1 items
        0	hdfs://localhost/user/training/hadoop3/retail/customers.txt 
        ### 13. hadoop fs -rm hadoop3/retail/customers.txt
        Deleted hdfs://localhost/user/training/hadoop3/retail/customers.txt 
        ### 14. hadoop fs -Is hadoop3/retail/customers.txt
        Is: Cannot access hadoop3/retail/customers.txt: No such file or directory. 
        ### 15. hadoop fs -rm hadoop3/retail/*
        ### 16. hadoop fs -expunge
        
        ### 17. hadoop fs -rmr hadoop3/retail
        
        Deleted hdfs://localhost/user/training/hadoop3/retail 
        ### 18. hadoop fs -Is hadoop3
         
        
        Found 1 items
        -rw-r--r--  1 training supergroup	0 2022-07-28 22:30 /user/training/hadoop3/sample.txt 
        ### 19. hadoop fs -copyFromLocal /home/training/purchases.txt hadoop3/
        ### 20. hadoop fs -cat hadoop3/purchases.txt dummy purchase
        ### 21. hadoop fs -copyToLocal hadoop3/purchases.txt /home/training/data 
        ### 22. hadoop fs -cp /user/training/*.txt /user/training/hadoop3
        ### 23. hadoop fs -get hadoop3/sample.txt /home/training/ 
        ### 24. hadoop fs -tail hadoop3/purchases.txt
        dummy purchase
        
        ### 25. hadoop fs -chmod 600 hadoop3/purchases.txt
        
        ### 26. sudo -u hdfs hadoop Is -chown root:root /user/training/hadoop3/purchases.txt 
        ### 27. sudo -u hdfs hadoop fs -chgrp training /user/training/hadoop3/purchases.txt hadoop fs -Is hadoop3/purchases.txtFound 1 items
        -rw-------  1 root training	15 2022-07-28 22:48 /user/training/hadoop3/purchases.txt 
        ### 28. hadoop fs -mv hadoop3 apache hadoop3
        ### 29. hadoop fs -setrep -w 2 apache hadoop3/sample.txt
        
        Replication 2 set: hdfs://localhost/user/training/apache_hadoop3/sample.txt Waiting for hdfs://localhost/user/training/apache_hadoop3/sample.txt .........
        
        ### 30. hadoop distcp hdfs://namenodeA/apache hadoop3 hdfs://namenodeB/hadoop3 
        ### 31. sudo -u hdfs hadoop dfsadmin -safemode leave
        Safe mode is OFF 
        ### 32. hadoop fs
        Usage: java FsShell
        [-Is ] [-Isr ]
        [-df []]
         
        [-du ] [-dus ]
        [-count[-q] ] [-mv  ] [-cp  ]
        [-rm [-skipTrash] ] [-rmr [-skipTrash] ] [-expunge]
        [-put  ... ]
        [-copyFromLocal  ...  ... ]
        [-get [-ignoreCrc] [-crc]  ] [-getmerge   [addnl]]
        [-cat  ] [-moveToLocal [-crc]  ]
        [-mkdir ]
        [-setrep [-R] [-w]  ] [-touchz ]
        [-stat [format] ] [-tail [-f] ]
        [-chmod [-R]  PATH...]
        [-chown [-R] [OWNER][:[GROUP]] PATH...] [-chgrp [-R] GROUP PATH...]
        [-help [cmd]]
        
        Generic options supported are
        -conf 	specify an application configuration file
        -D 	use value for given property
        -fs 	specify a namenode
        -jt 	specify a job tracker
        -files 	specify comma separated files to be copied to the map reduce cluster
        -libjars 	specify comma separated jar files to include in the classpath.
        -archives 	specify comma separated archives to be unarchived on the compute machines.
        
        The general command line syntax is
        bin/hadoop command [genericOptions] [commandoptions] 
        ### 33. hadoop fs -help
        hadoop fs is the command to execute fs commands. The full syntax is:

























create table emp (id INT, name STRING) row format delimited fields terminated by '1' stored as textfile

1. hive

2. show databases;

3. show tables;

4. create database bank;

5. use bank;

6. create table emp(id INT, name STRING, sal DOUBLE) row format delimited fields terminated by ',' stored as textfile;

7. describe emp;

8. create demo.txt in '/home/training/demo.txt'
	data:	10, raj, 1000
		20, rahul, 2000
		30, rohan, 3000
9. load data local inpath '/home/training/demo.txt'

10. select * from emp;

11. alter table emp rename to emp_sal;

12. select * from emp_sal where id=12;

13. select (*) count from emp_sal;

14. select avg(sal) as avg_salary from emp_sal;

15. select max(sal) as max_salary from emp_sal;

16. drop table emp_sal;

17. exit;




























R Codes:
 
1 Write a R program to create a Data Frame which contain details of 5 employees and display 
summary of the data using R.
 
# Create a data frame with employee details
employee_data <- data.frame(
  EmployeeID = c(1, 2, 3, 4, 5),
  Name = c("John", "Alice", "Bob", "Eve", "Charlie"),
  Age = c(30, 25, 28, 22, 35),
  Department = c("HR", "IT", "Finance", "Sales", "Marketing"),
  Salary = c(50000, 60000, 55000, 48000, 70000)
)
 
# Display the data frame
print(employee_data)
 
# Display a summary of the data
print(summary(employee_data))
 
2 For anydataset visialize the following types of chart : Scatterplot. Bubble Chart, Bar Chart ,  Dot Plots ,Histogram ,Box Plot ,Pie Chart
 
# Sample dataset
set.seed(123) # for reproducibility
data <- data.frame(
  X = rnorm(100),                 # Random numeric data for X-axis
  Y = rnorm(100),                 # Random numeric data for Y-axis
  Size = runif(100, 1, 10),      # Random sizes for bubbles
  Category = sample(letters[1:5], 100, replace = TRUE),  # Categories for bar chart and pie chart
  Value = rpois(100, 5)          # Random data for bar chart
)
 
# Scatterplot
plot(data$X, data$Y, main = "Scatterplot", xlab = "X-axis", ylab = "Y-axis")
 
# Bubble Chart
library(ggplot2)
ggplot(data, aes(x = X, y = Y, size = Size)) +
  geom_point() +
  labs(title = "Bubble Chart", x = "X-axis", y = "Y-axis")
 
# Bar Chart
barplot(table(data$Category), main = "Bar Chart", xlab = "Category", ylab = "Frequency")
 
# Dot Plot
stripchart(data$X, main = "Dot Plot", xlab = "X-axis")
 
# Histogram
hist(data$X, main = "Histogram", xlab = "X-axis")
 
# Box Plot
boxplot(data$X, main = "Box Plot")
 
# Pie Chart
pie(table(data$Category), main = "Pie Chart")
 
 
3 Write the script in R to sort the values contained in the following vector in ascending order 
and descending order: (23, 45, 10, 34, 89, 20, 67, 99). Demonstrate the output using graph
 
# Define the vector
values <- c(23, 45, 10, 34, 89, 20, 67, 99)
 
# Sort in ascending order
sorted_ascending <- sort(values)
 
# Sort in descending order
sorted_descending <- sort(values, decreasing = TRUE)
 
cat("Assending Order", sorted_ascending)
cat("\nDescending Order", sorted_descending)
 
# Create a bar plot to demonstrate the sorted values
par(mfrow = c(1, 2))  # Arrange two plots side by side
 
# Plot in ascending order
barplot(sorted_ascending, main = "Ascending Order", xlab = "Index", ylab = "Value")
 
# Plot in descending order
barplot(sorted_descending, main = "Descending Order", xlab = "Index", ylab = "Value")
 
 
4 The following table shows the number of units of different products sold on different days:
 
# Create numeric vectors for each product's daily sales
bread_sales <- c(12, 3, 5, 11, 9)
milk_sales <- c(21, 27, 18, 20, 15)
cola_cans_sales <- c(10, 1, 33, 6, 12)
chocolate_bars_sales <- c(6, 7, 4, 13, 12)
detergent_sales <- c(5, 8, 12, 20, 23)
 
# Create a vector of days
days <- c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday")
 
# Visualize the data using bar plots
par(mfrow = c(2, 3))  # Arrange the plots in a 2x3 grid
 
# Bread sales
barplot(bread_sales, names.arg = days, main = "Bread Sales", xlab = "Day", ylab = "Units Sold")
 
# Milk sales
barplot(milk_sales, names.arg = days, main = "Milk Sales", xlab = "Day", ylab = "Units Sold")
 
# Cola Cans sales
barplot(cola_cans_sales, names.arg = days, main = "Cola Cans Sales", xlab = "Day", ylab = "Units Sold")
 
# Chocolate Bars sales
barplot(chocolate_bars_sales, names.arg = days, main = "Chocolate Bars Sales", xlab = "Day", ylab = "Units Sold")
 
# Detergent sales
barplot(detergent_sales, names.arg = days, main = "Detergent Sales", xlab = "Day", ylab = "Units Sold")
 
 
5 Create a subset of subject less than 4 by using subset () funcon and demonstrate the output.
 Create a subject where the subject column is less than 3 and the class equals to 2 by using [] 
brackets and demonstrate the output using R
 
# Create the data frame
data <- data.frame(
  Subject = 1:6,
  Class = c(1, 2, 1, 2, 1, 2),
  Marks = c(56, 75, 48, 69, 84, 53)
)
 
# i) Create a subset of subjects less than 4
subset_result <- subset(data, Subject < 4)
 
# Show the subset result
print("Subset of subjects less than 4:")
print(subset_result)
 
# ii) Create a subset using [] brackets
subset_result2 <- data[data$Subject < 3 & data$Class == 2, ]
 
# Show the subset result
print("Subset using [] brackets:")
print(subset_result2)
 
# iii) Visualize the data
# Load the ggplot2 library for visualization
library(ggplot2)
 
# Create a scatterplot
p <- ggplot(data, aes(x = Subject, y = Marks)) + geom_point() + labs(title = "Scatterplot of Marks by Subject", x = "Subject", y = "Marks")
print(p)
 
 
6 The data analyst of Argon technology Mr. John needs to enter the salaries of 10 employees in 
R. The salaries of the employees are given in the following table: 
 
# i)
# Create a data frame with the initial salaries data
employee_data <- data.frame(
  "SrNo" = 1:10,
  "NameOfEmployees" = c("Vivek", "Karan", "James", "Soham", "Renu", "Farah", "Hetal", "Mary", "Ganesh", "Krish"),
  "Salaries" = c(21000, 55000, 67000, 50000, 54000, 40000, 30000, 70000, 20000, 15000)
)
 
# Display the employee_data data frame
print(employee_data)
 
# ii)
# Create a data frame for the new employees
new_employees <- data.frame(
  "SrNo" = 11:15,
  "NameOfEmployees" = c("John", "Sarah", "Emily", "Tom", "Lisa"),
  "Salaries" = c(48000, 60000, 52000, 45000, 58000)
)
 
# Combine the new data with the existing data
combined_data <- rbind(employee_data, new_employees)
 
# Display the combined data
print(combined_data)
 
 
#iii)
# Load the ggplot2 library for visualization
library(ggplot2)
 
# Create a bar chart to visualize salaries
p <- ggplot(combined_data, aes(x = reorder(`NameOfEmployees`, -Salaries), y = Salaries)) +
  geom_bar(stat = "identity") +
  labs(title = "Salaries of Employees", x = "Employee Names", y = "Salary") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
 
print(p)
 
 
 
7 Analyse and visualize churn modelling data using R.
 
# Load the churn modeling data
churn_data <- read.csv("E:\\Thadomal Shahani Engineering College\\Sem 7\\Assignments\\Big Data Analysis\\Pracs and Viva\\BDA Datasets\\Churn_Modelling.csv", header = TRUE)
 
# Exploratory Data Analysis (EDA)
cat("First few rows of the dataset:\n")
print(head(churn_data))
cat("\nDataset structure:\n")
print(str(churn_data))
cat("\nSummary statistics for the dataset:\n")
print(summary(churn_data))
 
# Data Visualization
par(mfrow = c(2, 2))  # Arrange plots in a 2x2 grid
 
# Histogram for Age
hist(churn_data$Age, main = "Distribution of Age", xlab = "Age")
 
# Boxplot for CreditScore by Geography
boxplot(CreditScore ~ Geography, data = churn_data, main = "CreditScore by Geography")
 
# Barplot for Gender
barplot(table(churn_data$Gender), main = "Gender Distribution", xlab = "Gender")
 
# Pie chart for Churn Rate
churn_rate <- mean(churn_data$Exited) * 100
labels <- c("Churned", "Not Churned")
sizes <- c(churn_rate, 100 - churn_rate)
pie(sizes, labels, main = "Churn Rate", col = c("red", "green"))
 
# Churn Analysis
overall_churn_rate <- sum(churn_data$Exited) / nrow(churn_data) * 100
churn_by_geography <- aggregate(Exited ~ Geography, data = churn_data, FUN = function(x) sum(x) / length(x) * 100)
churn_by_gender <- aggregate(Exited ~ Gender, data = churn_data, FUN = function(x) sum(x) / length(x) * 100)
 
cat("\nOverall Churn Rate: ", overall_churn_rate, "%\n")
cat("\nChurn Rate by Geography:\n")
print(churn_by_geography)
cat("\nChurn Rate by Gender:\n")
print(churn_by_gender)
 
 
8 Analyse and visualize IRIS data using R.
 
 
# Load the IRIS dataset
data(iris)
 
# Exploratory Data Analysis (EDA)
cat("First few rows of the dataset:\n")
head(iris)
cat("\nDataset structure:\n")
str(iris)
cat("\nSummary statistics for the dataset:\n")
summary(iris)
 
# Data Visualization
par(mfrow = c(2, 2))  # Arrange plots in a 2x2 grid
 
# Histogram for Sepal.Length
hist(iris$Sepal.Length, main = "Distribution of Sepal.Length", xlab = "Sepal.Length")
 
# Boxplot for Sepal.Length by Species
boxplot(Sepal.Length ~ Species, data = iris, main = "Boxplot of Sepal.Length by Species")
 
# Scatterplot for Sepal.Length vs. Sepal.Width
plot(iris$Sepal.Length, iris$Sepal.Width, pch = 19, col = iris$Species, main = "Sepal Length vs. Sepal Width", xlab = "Sepal Length", ylab = "Sepal Width")
legend("topright", legend = levels(iris$Species), col = 1:3, pch = 19)
 
# Pair Plot
library(GGally)
ggpairs(iris, columns = 1:4, aes(color = Species))
 
# Statistical Analysis
cat("Mean of Sepal.Length by Species:\n")
aggregate(Sepal.Length ~ Species, data = iris, FUN = mean)
 
cat("\nCorrelation Matrix:\n")
cor(iris[, 1:4])
 
 
 9 Analyse and visualize supermarket data using R.
 
# Load the supermarket data
supermarket_data <- read.csv("E:\\Thadomal Shahani Engineering College\\Sem 7\\Assignments\\Big Data Analysis\\Pracs and Viva\\BDA Datasets\\supermarket_sales.csv", header = TRUE)
 
# Exploratory Data Analysis (EDA)
cat("First few rows of the dataset:\n")
print(head(supermarket_data))
cat("\nDataset structure:\n")
print(str(supermarket_data))
cat("\nSummary statistics for the dataset:\n")
print(summary(supermarket_data))
 
# Data Visualization
par(mfrow = c(2, 2))  # Arrange plots in a 2x2 grid
 
# Histogram for Unit price
hist(supermarket_data$Unit.price, main = "Distribution of Unit Price", xlab = "Unit Price")
 
# Barplot for Branch
barplot(table(supermarket_data$Branch), main = "Branch Distribution", xlab = "Branch")
 
# Scatterplot for Quantity vs. `Unit price`
plot(supermarket_data$Quantity, supermarket_data$`Unit price`, pch = 19, main = "Quantity vs. Unit Price", xlab = "Quantity", ylab = "Unit Price")
 
# Barplot for Customer type
plot(supermarket_data$Quantity, supermarket_data$`Unit price`, pch = 19, main = "Quantity vs. Unit Price", xlab = "Quantity", ylab = "Unit Price", xlim = c(0, max(supermarket_data$Quantity)), ylim = c(0, max(supermarket_data$Unit.price)))
 
# Sales Analysis
total_sales_by_branch <- tapply(supermarket_data$`Total`, supermarket_data$Branch, sum)
top_selling_products <- names(sort(table(supermarket_data$Product.line), decreasing = TRUE)[1:5])
gross_income_by_branch <- tapply(supermarket_data$gross.income, supermarket_data$Branch, sum)
 
cat("\nTotal Sales by Branch:\n")
print(total_sales_by_branch)
cat("\nTop Selling Products:\n")
print(top_selling_products)
cat("\nGross Income by Branch:\n")
print(gross_income_by_branch)
 
 
10 Analyse and visualize Loan data using R
 
# Load the loan data
loan_data <- read.csv("E:\\Thadomal Shahani Engineering College\\Sem 7\\Assignments\\Big Data Analysis\\Pracs and Viva\\BDA Datasets\\loan_data_set.csv", header = TRUE)
 
# Exploratory Data Analysis (EDA)
cat("First few rows of the dataset:\n")
print(head(loan_data))
cat("\nDataset structure:\n")
print(str(loan_data))
cat("\nSummary statistics for the dataset:\n")
print(summary(loan_data))
 
# Data Visualization
par(mfrow = c(2, 2))  # Arrange plots in a 2x2 grid
 
# Histogram for ApplicantIncome
hist(loan_data$ApplicantIncome, main = "Applicant Income Distribution", xlab = "Applicant Income")
 
# Barplot for Gender
barplot(table(loan_data$Gender), main = "Gender Distribution", xlab = "Gender")
 
# Scatterplot for ApplicantIncome vs. CoapplicantIncome
plot(loan_data$ApplicantIncome, loan_data$CoapplicantIncome, pch = 19, main = "Applicant Income vs. Coapplicant Income", xlab = "Applicant Income", ylab = "Coapplicant Income")
 
# Barplot for Loan_Status
barplot(table(loan_data$Loan_Status), main = "Loan Status Distribution", xlab = "Loan Status")
 
# Loan Approval Analysis
approval_by_gender <- table(loan_data$Gender, loan_data$Loan_Status)
approval_by_education <- table(loan_data$Education, loan_data$Loan_Status)
credit_history_approval <- table(loan_data$Credit_History, loan_data$Loan_Status)
 
cat("\nLoan Approval by Gender:\n")
print(approval_by_gender)
cat("\nLoan Approval by Education:\n")
print(approval_by_education)
cat("\nCredit History vs. Loan Approval:\n")
print(credit_history_approval)
